[{"title":"MLSys 学习笔记 1","url":"/2025/04/17/MLSys-杂记1/","content":"1. GPU ECC（Error‑Correcting Code） 原理：在显存（VRAM）中为每 N 位数据生成冗余校验位，常见为 SECDED（单错纠正、双错检测）。 实现： 专业级卡（Tesla/Quadro/A100、AMD Instinct）默认支持 ECC，消费级卡多关闭或不支持。 ECC 逻辑集成在内存控制器，对程序透明。 优缺点： 优点：避免显存位翻转导致的 Silent Data Corruption，可监控纠错/未纠错计数。 缺点：约 12.5% 显存开销、5–12% 带宽与延迟损失。 开启与监控（NVIDIA 举例）: 2. NVIDIA Persistence Mode（持久化模式） 作用：驱动在无客户端时依然保持 GPU 上下文初始化，减少短作业启动延迟；保持稳定 P‑state。 命令： 注意：功耗略增；可配合 nvidia-persistenced 守护进程跨重启生效。 3. Ring Reduce（All‑Reduce）算法概览 分段（Scatter）：将张量平分 N 段，每轮只在环上沿顺时针传递一段。 Reduce‑Scatter：经过 N–1 轮，每段在环上累加所有节点后恰好落在一个归属节点上。 All‑Gather：再用同样方式广播各段结果，让所有节点拿到完整聚合值。 通信成本： Reduce‑Scatter：每节点发送/接收 数据量 All‑Gather：同理 合计 All‑Reduce： 4. Reduce‑Scatter 详细示例（4 节点、向量长 4） 初始数据 分段规则：下标 0→Seg 0，1→Seg 1，…，3→Seg 3。 3 轮累加： Segment 轮 1 累加结果 轮 2 累加结果 轮 3 累加结果 最终归属节点 全局和 0 5 + 1 = 6 9 + 6 = 15 13 + 15 = 28 Node 3 28 1 10 + 6 = 16 14 + 16 = 30 2 + 30 = 32 Node 0 32 2 15 + 11 = 26 3 + 26 = 29 7 + 29 = 36 Node 1 36 3 4 + 16 = 20 8 + 20 = 28 12 + 28 = 40 Node 2 40 结果：各节点分别持有自己负责 Segment 的全局和，为后续 All‑Gather 做准备。","date":"2025-04-17","tags":["GPU","ECC","持久化模式","Ring Reduce","Reduce-Scatter"]},{"title":"Parentheses Problems","url":"/2023/09/17/Parentheses-Problems/","content":"Parentheses is a kind of interesting problem, it is mainly related to valid parentheses like: Check whether the string is a valid parentheses Find the longest valid parentheses (substring) in a substring Find the longest valid parentheses (subsequence) in a substring Generate all valid parentheses for given length … Before dive into each topic, let’s define what is a valid parentheses. (), ()()()() and ((((((()))))))(())().","date":"2023-09-17","categories":["Algorithm"],"tags":["String"]},{"title":"RateLimiter Algorithm","url":"/2023/09/09/RateLimiter/","content":"RateLimiter is a curcial component in a distributed system. Normally we can used it to avoid DDoS or malicious request.In this post, we are going the introduce several algorithm that can be used to do Rate Limiting. Token BucketA token bucket is a container that has pre-defined capacity. Tokens are put in the bucket at preset rates periodically. Once the bucket is full, no more tokens are added. As shown in Figure, the token bucket capacity is 4. The refiller puts 2 tokens into the bucket every second. Once the bucket is full, extra tokens will overflow. Token Bucket can handle burst request and can make sure the limit won’t exceed the preset capacity. Leaking BucketLeaking Bucket is like Token Bucket but it acts like a FIFO queue. The leaking bucket has a process rate which indicate how many requestsit can processs per seconds. And when a request come, it will first check whether the queue is full or not, if not, add the request to the queue, otherwise drop the request.Request in the queue are pulled from the queue and processed at regulard intervals. One concern with Leaking Bucket is that it was processed in an FIFO way, if the queue was filled with old request, new request will be rate-limited.","date":"2023-09-09"},{"title":"Golang Tutorial 1","url":"/2023/09/08/Golang-Tutorial-1/","content":"","date":"2023-09-08"},{"title":"Rust Tutorial 1","url":"/2023/09/08/Rust-Tutorial-1/","content":"","date":"2023-09-08"},{"title":"Backtracking Template","url":"/2023/09/02/Backtracking-Template/","content":"回溯算法回溯算法通常用于搜索解空间。这样的解空间往往是组合爆炸式增长的，比如排列问题就是一个典型示例。 给定一个数字 ，打印出区间 中所有数字的排列。 对于 ，期望输出： 在这种情况下，我们需要使用回溯来解决问题。回溯会在每次做出决策、选择一个候选项扩展时保存一个“检查点”。 下面给出回溯算法的模板： 下面对排列问题做一个部分“手动演练”：1. 从 candidates 中选出 1，并移除它2. 从剩余中选出 2，并移除它3. 再选出 3，并移除它4. 此时 candidates 为空，跳出，记录排列 [1,2,3]5. 把 3 加回 candidates，但此时已无其他候选6. 把 2 加回 candidates，移动到下一个候选 37. 从 candidates 中选出 3，并移除它8. 再选出 2，并移除它9. candidates 为空，跳出，记录排列 [1,3,2]10. 依此类推… 显然，这里的时间复杂度并不是线性的，实际上与叶子节点数量一致，为 。","date":"2023-09-02","categories":["Algorithm"],"tags":["Backtracking"]},{"title":"LangChain","url":"/2023/08/20/LangChain/","content":"LangChain is a framework that","date":"2023-08-20","categories":["AI"],"tags":["LLM","AI"]},{"title":"Docker备忘录","url":"/2023/08/15/Docker-Memo/","content":"DockerfileDockerfile是一个包含容器镜像定义的文本文件，可用于启动容器。这个定义包含命令、基础镜像、配置等。在这篇文章中，我们将介绍每个组件，并讨论在什么场景下使用它们。让我们开始吧。 Docker镜像在深入了解各个组件之前，我们可能想知道Docker镜像到底是什么。参考：镜像的结构 镜像是一个只读模板，包含创建Docker容器的指令。通常，一个镜像是基于另一个镜像，并进行一些额外的定制。–Docker官方 Docker镜像可以包含很多文件，为了深入了解细节，让我们先拉取一个镜像。 从上面的输出中，我们知道我们从dockerhub拉取了python:alpine3.18镜像，这个镜像有5层。 基础镜像 &#x2F; 父镜像在大多数Dockerfile中，你会看到的第一行是FROM &#123;基础镜像&#125;，比如FROM python:3.8。 这一行定义了我们要构建的镜像的基础镜像。基础镜像可能包含一个或多个层。 RUNRUN命令可用于执行一些命令，如安装包、下载文件等。需要提到的一点是，每个命令都会在现有镜像上添加一个新层。将多个命令合并到一个RUN命令中是减小镜像大小和减少层数的常用技巧。 CMDCMD描述默认的容器参数或命令。用户可以在使用时轻松覆盖默认命令。 ENTRYPOINTENTRYPOINT也用于定义始终运行的命令，这意味着它不能被覆盖。ENTRYPOINT可用于确保容器启动时始终运行特定命令，即使用户尝试覆盖它。 COPYCOPY可用于将本地文件复制到容器镜像中，仅此而已。 ADDADD命令也允许将文件&#x2F;文件夹从主机复制到镜像。它支持tarball提取和远程URL支持。通常，ADD比COPY更受欢迎。现在让我们看一个在Dockerfile中使用ADD的例子。 假设我们在一个文件夹/tmp/app中，它有以下文件， 同时，我们在Dockerfile中写入以下命令。 上述命令将文件/tmp/app/server.js（主机路径）复制到/tmp/server.js（容器镜像路径）。我们注意到第一个参数应该在上下文内，上下文可以解释为我们执行docker build命令的路径。 VOLUME卷可以被视为Docker容器的持久数据存储。以下命令意味着从此镜像启动的任何容器，主机上的/var/www/html目录将被挂载到容器内的/var/www/html目录。这意味着在容器内对/var/www/html目录所做的任何更改都将反映在主机上，反之亦然。 DiveDive是一个非常有用的工具，用于分析容器镜像。它使你能够看到每一层的命令和反映在文件系统上的变化。 参考 OCI镜像清单规范","date":"2023-08-15","categories":["云计算"],"tags":["容器","Docker"]},{"title":"SQL Chapter 2 各种JOINS","url":"/2023/08/13/SQL-Chapter-2-各种JOINS/","content":"Chapter 2 各种JOINSInner join join with different database Self Join: compound join condition implicit join syntax Outer joins outer join with mutiple tables USING natural join — cross join Unions:","date":"2023-08-13","tags":["MYSQL"]},{"title":"SQL Chapter 1 intro/LIKE/LIMIT/REGEXP/IS NULL","url":"/2023/08/13/SQL-Chapter-1-intro-LIKE-LIMIT-REGEXP-IS-NULL/","content":"Chapter 1 intro&#x2F;LIKE&#x2F;LIMIT&#x2F;REGEXP&#x2F;IS NULLUSE sql_store; – use this database AND has a higher presidence than OR 括号里是and BETWEEN AND LIKE REGEXP IS NULL&#x2F; IS NOT NULL 新命名一列 &#x2F; ORDER BY LIMIT (可以skip）","date":"2023-08-13","tags":["MYSQL"]},{"title":"Linux System Overview","url":"/2023/08/08/Linux-System-Overview/","content":"Linux is probably the most widely used operation system in this world. Knowing the fundamental of Linux System could benfit developer in a lot of aspects. In this blog, we will explore some fundamental topics. File SystemYou can find a more detailed File system Hierarchy here. KernelEnvironment VariablePATHPATH is one of the most important environment variable. By default, it will have the value of When you type a command, it will search all the above folders and find whether there’s a file with same name can be found. The user need to have the permission to execute the file other wise it will raise a permission error zsh: permission denied: db.json. External Devices","date":"2023-08-08","categories":["Overview"],"tags":["Linux"]},{"title":"Random Algorithm","url":"/2023/08/08/Random-Algorithm/","content":"Weighed random()random() is an important function that will return a random number with same probability. Weighed random() requires us to generate random number with different weights. A naive approach could be we can create an array of elements. And we randomly set elements to , elements to , elements to and elements to .Then we can randomly pick an index from to , and reutrn the value on the picked index. However, the above method has a really obvious drawback. It will consume a lot memory and setting value will take a lot time as well. Instead of creating an array, can we compress the info there ? Ther answer is yes, let’s think about the prefix sum array of the weights array of size (0-indexed). $$w’k = \\sum_0^{k-1} w_i$$Then given an array, we have and $w’{n+1} = \\sum_0^{n} w_inD_i:[w’i, w’{i+1}],\\ i \\in {0,1 \\dots n}W’kkD_i\\frac{w_i}{\\sum_0^{n-1} w_j}$. Shuffle AlgorithmFisher–Yates shuffle Algorithm can be used to generate randomized permutation of array. The principal behind the algorithm is that we need to make sure each pair of index i.e need to have the same probablity of exchange. In the above implementation, for each , we randomly choose a that to conduct exchange. Note that we also include since it’s possible we don’t change it at all. In this way, we are able to cover all pairs , and as we iterate i from to , we will be able to cover all pairs.","date":"2023-08-08","categories":["Algorithm"],"tags":["Randomize"]},{"title":"Monotonic Stack/Queue","url":"/2023/08/06/Monotonic-Stack-Queue/","content":"","date":"2023-08-06","tags":["Data Structure"]},{"title":"并查集","url":"/2023/08/06/Union-Find/","content":"","date":"2023-08-06","tags":["数据结构"]},{"title":"Trie Tree","url":"/2023/08/06/Trie-Tree/","content":"","date":"2023-08-06","tags":["Data Structure"]},{"title":"树状数组","url":"/2023/08/06/Fenwick-Tree/","content":"树状数组，也称为二进制索引树，是一种支持单点更新和区间查询的数据结构。在大多数情况下，我们可以用它来查询区间和、区间乘积或其他满足以下条件的操作： 结合律： 具有逆运算，我们可以通过 和 推断出 它基于这样一个假设：任何前缀 都可以分解为最多 个区间，这些区间的信息是已知的。 从上图可以看出，每个位置 控制的区间的右边界是 。在树状数组中， 被分配控制长度为 的区间。这里， 是从右边数第一个 1 位的位置减 1。例如，$12 = (1100)2，则k = 2，2^k = 4。所以在这种情况下，c{12}控制的区间是[12 - 4 + 1, 12]。2^k可以使用函数获得，即x\\ & \\ (-x)$。","date":"2023-08-06","categories":["算法"],"tags":["数组","数据结构","位运算技巧"]},{"title":"Segment Tree","url":"/2023/08/06/Segment-Tree/","content":"Segment trees are a data structure commonly used to maintain interval information. Segment trees can be implemented in time complexity to perform operations such as single point update, range update, and range query (sum of range, maximum of range, minimum of range).","date":"2023-08-06","categories":["Algorithm"],"tags":["Data Structure","Segment Tree"]},{"title":"一致性哈希","url":"/2023/08/06/Consistent-Hashing/","content":"一致性哈希是一种常用于分布式系统的技术，用于将数据分布到不同的服务器/服务/数据中心。它可以确保： 数据 -> 节点映射是使用哈希函数计算的，数据 将被发送到第一个哈希值 的节点 当添加/删除节点时，只有部分数据需要重新映射，大多数数据不会受到影响。 与传统的哈希映射相比，一致性哈希可以实现更均衡的数据分布 方法论以下是一致性哈希工作原理的简要图示。 一致性哈希尝试执行以下操作： 创建一个哈希环 并均匀地将现有节点分布在环上。 计算数据的哈希值，并将其发送到具有更大哈希值的第一个节点。 当S3节点被移除时，只有 范围内的数据会被重新映射到S2。 上述一致性哈希看起来不错，但是，一些服务器可能会过载，而一些服务器则一直处于空闲状态。在这种情况下，我们可能会观察到，大部分数据的哈希值落入一个范围，即 ，这是整个哈希环的一个子域。 在上图中，大多数ID落入IP2的范围内，这表示分布不均衡。为了解决这个问题，我们引入了虚拟节点来更均匀地分配工作负载。 与在哈希环上只有一个节点代表物理服务器不同，我们实际上创建了多个虚拟节点并将它们分布在哈希环域上。在这种情况下，如果数据落入一个子域，我们仍然可以将它们映射到不同的物理服务器。同时，如果我们添加或删除节点，受影响的范围将比简单的一致性哈希小得多，因为每个段将小得多。","date":"2023-08-06","categories":["系统设计"]},{"title":"System Design Fundamentals","url":"/2023/08/06/System-Design-Fundamentals/","content":"CAP TheoremThe CAP theorem, or Brewer’s theorem, states that a distributed database system can only guarantee two out of three characteristics: consistency, availability, and partition tolerance. The system prioritizes availability over consistency and can respond with possibly stale data. Partition Tolerance在CAP理论中,Partition Tolerance(分区容忍性)是指系统在发生网络分区故障的时候,仍然能够对外提供服务的能力。 所谓网络分区故障,是指系统中的节点被分成两部分,节点间的网络通信被阻断。在这种情况下,一个分布式系统可能会表现出下面两种行为: 无法对外提供服务 整个系统不可用,对用户不可见。 以牺牲一致性为代价继续服务 系统继续对用户可见,但返回的数据可能不一致。 Partition Tolerance表示系统能够承受网络分区的发生,继续对外服务而不会完全崩溃。根据CAP理论,一个系统不可能同时满足一致性(Consistency)、可用性(Availability)和分区容忍性,最多只能同时满足两个。 所以一个Partition Tolerance系统通常会牺牲数据一致性来保证服务可用性。比如允许读取到过期数据,或两个分区的数据产生冲突。这在许多大规模分布式系统中都是可接受的权衡。 一个典型的Partition Tolerance(分区容忍性)的例子是DNS系统。 DNS采用了分布式的树形结构,一个域名由多个DNS服务器共同提供解析服务。当网络发生分区时,可能出现如下情况: 某区域用户无法访问部分DNS服务器,但可以访问到另一部分服务器,仍能得到域名解析结果。 不同的DNS服务器返回了不同的解析结果(IP地址不一致),但用户还是能得到响应。 这就是DNS系统表现出来的Partition Tolerance性质。当网络分区发生时,DNS系统为了继续服务,承受返回不一致数据的结果,而没有选择完全停止响应。 Partition Tolerance的另一个例子是一些分布式缓存系统,如Memcached。当节点间失去联系时,不同分区的数据可能不一致,但每个分区内部仍能继续使用本地缓存,整个系统不会完全停止服务。 这些系统都采用了设计理念:“允许读取脏数据”或者“允许短暂不一致”来实现Partition Tolerance。因为对大多数应用来说,与整个系统完全不可用相比,读取到陈旧或不一致的数据仍是可以接受的。 Modern Distrbuted System ComponentsLoad BalancerLoad Balancer is the entry point of an web application. It will distribute incoming customer traffic to difference worker&#x2F;servers. It can help Avoid a single server to be overloaded Redirect request to healthy server when one server become unavailable. Load Balancer plays an important role in enabling system to scale horizontally. AWS provides the following load balancer services: Classic Load Balancer: mainly used to distribute traffic to EC2 instances Application Load Balancer: more flexible, choose this one by default. Network Load Balancer Gateway Load Balancer CDNContent Delivery Network(CDN) is a service provided by third-party for fast file delivery. By providing a single endpoint, CDN servie will automatically route to the closet server to fetch the static files. It is mainly used to serve static files like HTML, javascript file and images. It can also host some files like video, tarball etc. It can: Reduce the load of web server Accelerate the file retrievel by fetching file from closest server. There is a TTL(Time to live) need to set for CDN. If TTL is set to be a small value, it will need to update the cache from source very often, the charge of data transfer will increase. If TTL is set to be a large value, customer may get stale file. The TTL should be set according to the need of system. DNSThe Domain Name System (DNS) is a database that translates domain names into Internet Protocol (IP) addresses. DNS maps the name that people use to locate a website to the IP address that a computer uses to locate that website. Web TierWeb Tier mainly refers to Web Service. Web service mainly contains business logic. Like fetching the data from database and return to user or submit an order on behalf of user etc. Ideally, web tier should be stateless since it can make web tier eailer to scale horizontally. Data TierData Tier mainly refers to database or persistent storage. The “persistent” means even if the server shut down, the data will not be lost. On the contaray, some in-memory cache system will lose all data if server get shut down. As data becomes more and more complex, people developed various data base system to accomodate different use case. Relational Database NoSQL (Not only SQL) Giving an expressive decription of database here would be too ambitious, we will use a single post to discuss it in detail. Cache TierCacher Tier emerges as querying database is such an expensive operation. In the mean while, some request can also be expensive like running a model to give calculation. Thanks to the Principle of Locality, we know the tendency of a processor to access the same set of memory locations repetitively over a short period of time. It means that the same data could be used multiple times over a short period of time. And that makes cache tier useful in real production. Cache works as a middle-ware inside the system and it can be scaled idenpendently. It also brings a series of challenges like cache overheat, cache missing and data synchronization. Like data tier, we will use a single post to discuss it in detail. Message QueueSometimes we may think if there’s chain of service calling. How could these subsystem to scale independently. i.e If service A is trying to call service B, if service B is not available at the time when service A made the call, then service A must wait, otherwise we will lose the request from customer. We may want something that can abstract service’s input producer and outcome consumer. Here is what message queue come into play. Message queues serve as temporary storage services. Producers can publish messages to a MQ regardless of whether consumers are working or not. At the same time, consumers can consume messages from a MQ regardless of whether producers are working or not.","date":"2023-08-06","categories":["System Design"],"tags":["Overview"]},{"title":"二叉树主题","url":"/2023/08/06/Binary-Tree-Topics/","content":"遍历关于二叉树遍历有很多有趣的主题，比如BST的中序遍历是一个有序序列。我们可能还想知道如何进行层次遍历（使用队列），这是进行广度优先搜索（BFS）的基础。在下面的每个部分中，我们将讨论这些主题。 前序遍历前序遍历将按照根节点 -> 左子节点 -> 右子节点的顺序访问。 中序遍历中序遍历将按照左子节点 -> 根节点 -> 右子节点的顺序访问。BST的中序遍历将返回一个有序数组。 后序遍历后序遍历将按照左子节点 -> 右子节点 -> 根节点的顺序访问。 要确定一棵二叉树，我们需要中序序列 + 前序&#x2F;后序序列。 解决二叉树问题的方法论一个重要的观察是，当我们查看根节点的位置时，从前序到后序，它从第一个变为最后一个。由于我们总是在访问右子节点之前访问左子节点，我们可以将不同遍历之间的差异仅视为何时对根节点进行操作。 然后我们可以将问题归纳为几种情况： 要对根节点进行操作，你需要先对左子树和右子树进行操作。（归并排序） 要对根节点进行操作，你需要先对其父节点进行操作。（获取二叉树的深度） 要对根节点进行操作，你需要先对左&#x2F;右子树进行操作。（检查BST） 上述三种情况大致涵盖了所有三种遍历方法。给定一个问题，我们需要注意对给定节点的操作是什么，以及何时进行操作。前序、中序还是后序？ 二叉搜索树（BST）是一种特殊的二叉树，对于给定的根节点，左子树只包含值小于根节点的节点，右子树只包含值大于根节点的节点。 经典主题&#x2F;问题以下是一些你可能想了解的著名主题和问题。 最低公共祖先最低公共祖先问题是尝试获取两个给定节点的最低公共祖先节点。 为了以适合上述3种情况的方式分析解决方案，让我们思考一下我们需要对单个节点做什么操作。基本上，我们需要遍历二叉树中的每个节点，以确定该节点是否是我们想要的LCA。对于给定节点，LCA可能是这个节点，但要确认这一点，我们需要确保两个目标节点都在它的子树中。这意味着除非我们完成检查它的左子树和右子树，否则我们无法确认这一点。这意味着它实际上是一个后序遍历。 二叉树的序列化和反序列化从有序数组创建BST从有序数组创建BST是另一个有趣的主题。 可能的BST给定一个有序数组，返回所有可能的BST。 BFS &#x2F; 层序遍历广度优先搜索&#x2F;层序遍历尝试扫描每一层并打印值。 层序遍历可以被视为前序遍历的扩展变体。对于前序遍历，我们对单个根节点进行操作，然后移动到其左子节点和右子节点。但对于层次遍历，我们可以将同一层的节点视为一个节点，在我们完成对这个”大节点”的操作后，我们移动到它的子节点。","date":"2023-08-06","categories":["算法"],"tags":["二叉树"]},{"title":"二进制快速幂","url":"/2023/08/06/Binary-Exponentiation/","content":"二进制快速幂二进制快速幂（简称BE）是一种可以加速幂运算计算的技术。对于朴素的幂运算 ，时间复杂度是 ，而使用二进制快速幂，时间复杂度降为 。让我们从一个例子开始， 假设 是一个32位整数，这意味着最多我们只需要计算32次，并检查 是否包含在内。 矩阵快速幂 矩阵快速幂主要用于线性递归计数问题，以及一些状态转移方程是线性递归关系的动态规划问题。有些计数问题可以通过手动推导小规模的n来观察模式，并猜测递归关系。如果这个递归关系是线性的，那么它可以转化为矩阵幂问题，并使用矩阵快速幂加速计算。","date":"2023-08-06"},{"title":"Patience Sorting","url":"/2023/08/06/Patience-Sorting/","content":"Patience SortingFrom wikipedia: Patience sorting is a sorting algorithm in computer science that uses the rules of the card game Patience to sort a list of elements by their values. The goal of the game is to form as few piles as possible. Pateince sorting can be used to solve Longest Increasing Sequence(LIS) problem. We can just skip the proof, feel free to refer document for detailed proof. The only thing we nned to know is that the number of piles is equal to the length of longest increasing sequence.","date":"2023-08-06","tags":["Divide and Conquer","LIS"]},{"title":"二分查找模板","url":"/2023/08/06/Binary-Search-Templates/","content":"二分查找二分查找可用于在有序序列中搜索或确定元素或枢轴。这里我们有三种使用二分查找的场景。 在唯一元素数组中查找元素 有时当数组中有重复元素时，我们可能想要找到目标元素的左边界或右边界，这时情况会变得复杂。但我们仍然有方法来做到这一点。 查找左边界 我们以上面的代码为例。首先我们需要定义搜索范围。 如果我们使用 while(left <= right)，这意味着我们的搜索范围是 。 如果我们使用 while(left < right)，这意味着我们的搜索范围是 ，因为left永远不会达到初始的right值。 对于这一行，当我们发现目标值等于 arr[mid] 时，我们不返回 mid，而是缩小右边界，这意味着对于 ，我们有 arr[i] >= target。另一方面，对于 left，它最终会进入 arr[i] >= target 的域，或者它会超出数组的范围。排除超出范围的情况后，我们有两种情况： arr[i] = target arr[i] > target 这是为了检查目标值是否存在于数组中。 查找右边界","date":"2023-08-06","categories":["算法"],"tags":["二分查找","分治法"]}]