<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <title>Create a PEFT Module Guideline | Tuntun&#39;s Blog</title>
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" integrity="sha512-9usAa10IRO0HhonpyAIVpjrylPvoDwiPUiKdWk5t3PyolY1cOd4DSE0Ga+ri4AuTroPR5aQvXU9xC6qOPnzFeg==" crossorigin="anonymous" referrerpolicy="no-referrer" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">

  <!-- 添加代码高亮样式 -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css">
  <!-- 添加highlight.js库 -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
  <!-- 添加mermaid.js库 -->
  <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
  <link rel="stylesheet" href="/css/code.css">
  <link rel="stylesheet" href="/css/code-custom.css">
  <link rel="stylesheet" href="/css/code-languages.css">
  <link rel="stylesheet" href="/css/mermaid.css">

  <link rel="stylesheet" href="/css/vscode.css">
  <link rel="stylesheet" href="/css/post.css">
  <link rel="stylesheet" href="/css/tag.css">
  <link rel="stylesheet" href="/css/categories.css">
  <link rel="stylesheet" href="/css/archive.css">
  <link rel="stylesheet" href="/css/search.css">
  <link rel="stylesheet" href="/css/mobile.css">  <link rel="stylesheet" href="/css/responsive.css">
  <link rel="stylesheet" href="/css/elements.css">

  <!-- 添加 JetBrains Mono 字体 -->  
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap" rel="stylesheet">

  <!-- Add any custom head content here -->

  <script src="/js/explorer.js"></script>
  <script src="/js/code-copy.js"></script>
  <script src="/js/code-enhance.js"></script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

  <body>
    <div class="wrapper">
      <div class="mobile-menu-toggle">
        <i class="fas fa-bars"></i>
      </div>
      <header class="vs-header">
  <nav class="vs-nav">
    <div class="nav-left">
      <a href="/" class="nav-brand">
        <i class="fas fa-terminal"></i>
        Tuntun&#39;s Blog
      </a>
    </div>
    
    <div class="nav-right">
      <a href="/" class="nav-item ">
        <i class="fas fa-home"></i>
        <span>Home</span>
      </a>
      <a href="/archives/" class="nav-item ">
        <i class="fas fa-archive"></i>
        <span>Archives</span>
      </a>
      <a href="/categories/" class="nav-item ">
        <i class="fas fa-folder"></i>
        <span>Categories</span>
      </a>
      <a href="/tags/" class="nav-item ">
        <i class="fas fa-tags"></i>
        <span>Tags</span>
      </a>
      <a href="/search/" class="nav-item ">
        <i class="fas fa-search"></i>
        <span>Search</span>
      </a>
      <a href="/about/" class="nav-item ">
        <i class="fas fa-info-circle"></i>
        <span>About</span>
      </a>
    </div>
  </nav>
</header>

<script>
  function smoothScroll(event, target) {
    event.preventDefault();
    const targetId = target.substring(target.indexOf('#') + 1);
    const targetElement = document.getElementById(targetId);

    if (targetElement) {
      window.scrollTo({
        top: targetElement.offsetTop - 50, // 调整偏移量
        behavior: 'smooth'
      });
    } else {
      window.location.href = target;
    }
  }

  window.addEventListener('scroll', function() {
    const header = document.querySelector('.vs-header');
    const nav = document.querySelector('.vs-nav');
    const scrollPercent = (window.scrollY / (document.documentElement.scrollHeight - window.innerHeight)) * 100;
    
    nav.style.setProperty('--scroll-percent', `${scrollPercent}%`);
    
    if (window.scrollY > 0) {
      header.classList.add('scrolled');
    } else {
      header.classList.remove('scrolled');
    }
  });

  // 添加标签页切换动画
  document.querySelectorAll('.nav-item').forEach(item => {
    item.addEventListener('click', function(e) {
      const ripple = document.createElement('span');
      ripple.classList.add('nav-ripple');
      this.appendChild(ripple);
      
      const rect = this.getBoundingClientRect();
      const x = e.clientX - rect.left;
      const y = e.clientY - rect.top;
      
      ripple.style.left = `${x}px`;
      ripple.style.top = `${y}px`;
      
      setTimeout(() => ripple.remove(), 1000);
    });
  });
</script>


<div class="vscode-container">
  <!-- 左侧资源管理器 -->
  <div class="sidebar-explorer">
    <!-- TOC导航 -->
    <div class="explorer-section">
      <div class="section-header">
        <i class="fas fa-list"></i>
        <span>TABLE OF CONTENTS</span>
      </div>
      <div class="section-content">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%A7%88"><span class="toc-text">概览</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="toc-text">一、准备工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%86%99%E9%85%8D%E7%BD%AE%EF%BC%88config-py%EF%BC%89"><span class="toc-text">二、写配置（config.py）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AE%9E%E7%8E%B0%E5%9F%BA%E7%A1%80-Adapter-Layer%EF%BC%88layer-py%EF%BC%89"><span class="toc-text">三、实现基础 Adapter Layer（layer.py）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%8B%BC%E8%A3%85%E6%A8%A1%E5%9E%8B%EF%BC%88model-py%EF%BC%89"><span class="toc-text">四、拼装模型（model.py）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%A4%BA%E4%BE%8B"><span class="toc-text">运行一个完整示例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Mix-Mode"><span class="toc-text">Mix Mode</span></a></li></ol>
      </div>
    </div>
    
    <!-- 同分类文章 -->
    
    
    <!-- 标签列表 -->
    
    <div class="explorer-section">
      <div class="section-header">
        <i class="fas fa-tags"></i>
        <span>ARTICLE TAGS</span>
      </div>
      <div class="section-content">
        
          <div class="tag-item">
            <i class="fas fa-tag"></i>
            <a href="/tags/PEFT/">PEFT</a>
            <span class="count">(2)</span>
          </div>
        
          <div class="tag-item">
            <i class="fas fa-tag"></i>
            <a href="/tags/LoRA/">LoRA</a>
            <span class="count">(2)</span>
          </div>
        
          <div class="tag-item">
            <i class="fas fa-tag"></i>
            <a href="/tags/Adapter/">Adapter</a>
            <span class="count">(1)</span>
          </div>
        
      </div>
    </div>
    
  </div>

  <!-- 主要内容区域 -->
  <div class="editor-content">
    <div class="tab-bar">
      <div class="tab active">
        <i class="fas fa-file-alt"></i>
        <span>Create a PEFT Module Guideline.md</span>
      </div>
    </div>
    
    <div class="content-area">
      <article class="post-content">
        <div class="post-header">
          <h1>Create a PEFT Module Guideline</h1>
          <div class="post-meta">
            <span class="date">
              <i class="fas fa-calendar-alt"></i>
              2025-04-30
            </span>            
            
              <span class="tags">
                <i class="fas fa-tags"></i>
                <div class="tags-list">
                  <ul class="tag-item-post-list" itemprop="keywords"><li class="tag-item-post-list-item"><a class="tag-item-post-list-link" href="/tags/Adapter/" rel="tag">Adapter</a></li><li class="tag-item-post-list-item"><a class="tag-item-post-list-link" href="/tags/LoRA/" rel="tag">LoRA</a></li><li class="tag-item-post-list-item"><a class="tag-item-post-list-link" href="/tags/PEFT/" rel="tag">PEFT</a></li></ul>
                </div>
              </span>
            
          </div>
        </div>
        
        <div class="post-body vscode-markdown">
          <h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>想在自己的仓库里“魔改”PEFT，最常见的套路是：  </p>
<ol>
<li>Clone 官方 <code>peft</code> 源码  </li>
<li>在 <code>tuner/</code> 里新建一个模块目录  </li>
<li>用可编辑安装（<code>pip install -e</code>）替换你项目中的 PEFT  </li>
<li>按需写 <code>config.py</code>、<code>layer.py</code>、<code>model.py</code></li>
</ol>
<p>下面我用 LoRA（低秩适配器）举例，带你一步步梳理如何从零创建一个可复用的 PEFT Module。读不懂的地方我会额外加个小标注👀，帮助你快速上手。</p>
<hr>
<h2 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h2><ol>
<li><p><strong>建仓库、拉源码</strong>  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">mkdir peft-mogai<br>cd peft-mogai<br>git clone https://github.com/huggingface/peft.git<br>pip install -e ./peft --config-settings editable_mode=compat<br></code></pre></td></tr></table></figure>
<blockquote>
<p><strong>注</strong>：<code>-e</code>（editable）模式可以让你改源码后，项目自动生效。</p>
</blockquote>
</li>
<li><p><strong>搭建模块目录</strong><br>在 <code>peft/peft/tuners/</code> 目录下，创建你自己的文件夹，比如 <code>lora_mogai/</code>：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs vim">peft/peft/tuners/<br>└── lora_mogai/<br>    ├── __init__.<span class="hljs-keyword">py</span><br>    ├── config.<span class="hljs-keyword">py</span><br>    ├── layer.<span class="hljs-keyword">py</span><br>    └── model.<span class="hljs-keyword">py</span><br></code></pre></td></tr></table></figure>
<ul>
<li><code>__init__.py</code>：导出你的 Config、Layer、Model。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># lora_mogai/__init__.py</span><br><span class="hljs-keyword">from</span> .config <span class="hljs-keyword">import</span> MogaiConfig<br><span class="hljs-keyword">from</span> .layer  <span class="hljs-keyword">import</span> MogaiLayer, Linear<br><span class="hljs-keyword">from</span> .model  <span class="hljs-keyword">import</span> MogaiModel<br><br>__all__ = [<span class="hljs-string">"MogaiConfig"</span>, <span class="hljs-string">"MogaiLayer"</span>, <span class="hljs-string">"Linear"</span>, <span class="hljs-string">"MogaiModel"</span>]<br></code></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="二、写配置（config-py）"><a href="#二、写配置（config-py）" class="headerlink" title="二、写配置（config.py）"></a>二、写配置（config.py）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># lora_mogai/config.py</span><br><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass, field<br><span class="hljs-keyword">from</span> typing       <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Optional</span>, <span class="hljs-type">Union</span><br><span class="hljs-keyword">from</span> peft.config  <span class="hljs-keyword">import</span> PeftConfig<br><span class="hljs-keyword">from</span> peft.utils   <span class="hljs-keyword">import</span> PeftType<br><br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MogaiConfig</span>(<span class="hljs-title class_ inherited__">PeftConfig</span>):<br>    r: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">256</span>, metadata={<span class="hljs-string">"help"</span>: <span class="hljs-string">"低秩映射维度"</span>})<br>    target_modules: <span class="hljs-type">Optional</span>[<span class="hljs-type">Union</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>], <span class="hljs-built_in">str</span>]] = field(<br>        default=<span class="hljs-literal">None</span>,<br>        metadata={<span class="hljs-string">"help"</span>: <span class="hljs-string">"要替换的模块名或正则，例如 ['q','v'] 或 '.*SelfAttention.*'"</span>}<br>    )<br>    mogai_alpha: <span class="hljs-built_in">int</span>   = field(default=<span class="hljs-number">8</span>,   metadata={<span class="hljs-string">"help"</span>: <span class="hljs-string">"LoRA 缩放系数 α"</span>})<br>    mogai_dropout: <span class="hljs-built_in">float</span> = field(default=<span class="hljs-number">0.0</span>, metadata={<span class="hljs-string">"help"</span>: <span class="hljs-string">"LoRA dropout prob"</span>})<br>    fan_in_fan_out: <span class="hljs-built_in">bool</span> = field(default=<span class="hljs-literal">False</span>, metadata={<span class="hljs-string">"help"</span>: <span class="hljs-string">"是否开启 fan_in_fan_out 模式"</span>})<br>    bias: <span class="hljs-built_in">str</span> = field(default=<span class="hljs-string">"none"</span>, metadata={<span class="hljs-string">"help"</span>: <span class="hljs-string">"bias 类型：'none'|'all'|'mogai_only'"</span>})<br>    modules_to_save: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = field(<br>        default=<span class="hljs-literal">None</span>,<br>        metadata={<span class="hljs-string">"help"</span>: <span class="hljs-string">"额外需要保存的随机初始化层"</span>}<br>    )<br>    layers_to_transform: <span class="hljs-type">Optional</span>[<span class="hljs-type">Union</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], <span class="hljs-built_in">int</span>]] = field(<br>        default=<span class="hljs-literal">None</span>,<br>        metadata={<span class="hljs-string">"help"</span>: <span class="hljs-string">"只转换指定的层索引"</span>}<br>    )<br>    layers_pattern: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = field(<br>        default=<span class="hljs-literal">None</span>,<br>        metadata={<span class="hljs-string">"help"</span>: <span class="hljs-string">"自定义层名称正则（配合 layers_to_transform）"</span>}<br>    )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__post_init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-variable language_">self</span>.peft_type     = PeftType.MOGAI<br>        <span class="hljs-variable language_">self</span>.target_modules = (<br>            <span class="hljs-built_in">set</span>(<span class="hljs-variable language_">self</span>.target_modules) <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(<span class="hljs-variable language_">self</span>.target_modules, <span class="hljs-built_in">list</span>) <span class="hljs-keyword">else</span> <span class="hljs-variable language_">self</span>.target_modules<br>        )<br></code></pre></td></tr></table></figure>

<blockquote>
<p>👀 <strong>为什么要继承 <code>PeftConfig</code>？</strong><br>它让你的 Config 能和 PEFT 主流程无缝对接，比如自动解析 CLI、序列化存盘等。</p>
</blockquote>
<hr>
<h2 id="三、实现基础-Adapter-Layer（layer-py）"><a href="#三、实现基础-Adapter-Layer（layer-py）" class="headerlink" title="三、实现基础 Adapter Layer（layer.py）"></a>三、实现基础 Adapter Layer（layer.py）</h2><p>核心思路：  </p>
<ol>
<li><strong>保存原始层 <code>base_layer</code></strong>  </li>
<li><strong>动态创建低秩矩阵</strong> A 和 B  </li>
<li><strong>在 <code>forward</code> 里叠加 delta = B(A(x))</strong></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># lora_mogai/layer.py</span><br><span class="hljs-keyword">import</span> math, warnings<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> peft.tuners.tuners_utils <span class="hljs-keyword">import</span> BaseTunerLayer<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MogaiLayer</span>(<span class="hljs-title class_ inherited__">BaseTunerLayer</span>):<br>    adapter_layer_names = (<span class="hljs-string">"mogai_A"</span>, <span class="hljs-string">"mogai_B"</span>)<br>    other_param_names   = (<span class="hljs-string">"r"</span>, <span class="hljs-string">"mogai_alpha"</span>, <span class="hljs-string">"scaling"</span>, <span class="hljs-string">"mogai_dropout"</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, base_layer: nn.Module, **kwargs</span>):<br>        <span class="hljs-variable language_">self</span>.base_layer = base_layer<br>        <span class="hljs-variable language_">self</span>.r            = {}<br>        <span class="hljs-variable language_">self</span>.mogai_alpha  = {}<br>        <span class="hljs-variable language_">self</span>.scaling      = {}<br>        <span class="hljs-variable language_">self</span>.mogai_dropout= nn.ModuleDict()<br>        <span class="hljs-variable language_">self</span>.mogai_A      = nn.ModuleDict()<br>        <span class="hljs-variable language_">self</span>.mogai_B      = nn.ModuleDict()<br>        <span class="hljs-variable language_">self</span>._disable_adapters = <span class="hljs-literal">False</span><br>        <span class="hljs-variable language_">self</span>.merged_adapters   = []<br><br>        base = <span class="hljs-variable language_">self</span>.get_base_layer()<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(base, nn.Linear):<br>            <span class="hljs-variable language_">self</span>.in_features, <span class="hljs-variable language_">self</span>.out_features = base.in_features, base.out_features<br>        <span class="hljs-variable language_">self</span>.kwargs = kwargs<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update_layer</span>(<span class="hljs-params">self, adapter_name, module_name, r, mogai_alpha, mogai_dropout</span>):<br>        <span class="hljs-keyword">if</span> r &lt;= <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f"`r` must be positive, got <span class="hljs-subst">{r}</span>"</span>)<br>        <span class="hljs-variable language_">self</span>.r[adapter_name]           = r<br>        <span class="hljs-variable language_">self</span>.mogai_alpha[adapter_name] = mogai_alpha<br>        <span class="hljs-variable language_">self</span>.scaling[adapter_name]     = mogai_alpha / r<br>        drop = nn.Dropout(p=mogai_dropout) <span class="hljs-keyword">if</span> mogai_dropout&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">else</span> nn.Identity()<br>        <span class="hljs-variable language_">self</span>.mogai_dropout[adapter_name] = drop<br><br>        <span class="hljs-variable language_">self</span>.mogai_A[adapter_name] = nn.Linear(<span class="hljs-variable language_">self</span>.in_features, r, bias=<span class="hljs-literal">False</span>)<br>        <span class="hljs-variable language_">self</span>.mogai_B[adapter_name] = nn.Linear(r, <span class="hljs-variable language_">self</span>.out_features, bias=<span class="hljs-literal">False</span>)<br>        nn.init.kaiming_uniform_(<span class="hljs-variable language_">self</span>.mogai_A[adapter_name].weight, a=math.sqrt(<span class="hljs-number">5</span>))<br>        nn.init.zeros_(<span class="hljs-variable language_">self</span>.mogai_B[adapter_name].weight)<br><br>        <span class="hljs-variable language_">self</span>._move_adapter_to_device_of_base_layer(adapter_name)<br>        <span class="hljs-variable language_">self</span>.set_adapter(<span class="hljs-variable language_">self</span>.active_adapter)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Linear</span>(nn.Linear, MogaiLayer):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, base_layer, adapter_name, module_name, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(nn.Linear, <span class="hljs-variable language_">self</span>).__init__()<br>        MogaiLayer.__init__(<span class="hljs-variable language_">self</span>, base_layer, **kwargs)<br>        <span class="hljs-variable language_">self</span>.update_layer(adapter_name, module_name, **kwargs)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">merge</span>(<span class="hljs-params">self, *args, **kwargs</span>):   <span class="hljs-keyword">raise</span> NotImplementedError<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">unmerge</span>(<span class="hljs-params">self, *args, **kwargs</span>): <span class="hljs-keyword">raise</span> NotImplementedError<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_delta_weight</span>(<span class="hljs-params">self, *args, **kwargs</span>): <span class="hljs-keyword">raise</span> NotImplementedError<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: torch.Tensor, *args, **kwargs</span>):<br>        orig_type = x.dtype<br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.disable_adapters <span class="hljs-keyword">or</span> <span class="hljs-variable language_">self</span>.merged:<br>            result = <span class="hljs-variable language_">self</span>.base_layer(x, *args, **kwargs)<br>        <span class="hljs-keyword">else</span>:<br>            result = <span class="hljs-variable language_">self</span>.base_layer(x, *args, **kwargs)<br>            <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.active_adapters:<br>                <span class="hljs-keyword">if</span> name <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.mogai_A: <span class="hljs-keyword">continue</span><br>                A = <span class="hljs-variable language_">self</span>.mogai_A[name]; B = <span class="hljs-variable language_">self</span>.mogai_B[name]<br>                drop, scale = <span class="hljs-variable language_">self</span>.mogai_dropout[name], <span class="hljs-variable language_">self</span>.scaling[name]<br>                y = drop(x.to(A.weight.dtype))<br>                result = result + F.linear(F.linear(y, A.weight), B.weight) * scale<br>        <span class="hljs-keyword">return</span> result.to(orig_type)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__repr__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">"mogai."</span> + <span class="hljs-built_in">super</span>().__repr__()<br></code></pre></td></tr></table></figure>

<blockquote>
<p>👀 <strong>小贴士</strong>：  </p>
<ul>
<li>把所有 adapter 参数都放到 <code>ModuleDict</code> 里，方便按名字管理；  </li>
<li>初始把 B 置零，可以保证训练初期模型行为和原模型一致。</li>
</ul>
</blockquote>
<hr>
<h2 id="四、拼装模型（model-py）"><a href="#四、拼装模型（model-py）" class="headerlink" title="四、拼装模型（model.py）"></a>四、拼装模型（model.py）</h2><p>在 <code>model.py</code> 中，我们用 <code>MogaiModel</code> 继承自 PEFT 的 <code>BaseTuner</code>，核心作用是：</p>
<ol>
<li><strong>扫描并替换</strong>：在 <code>_create_and_replace</code> 方法里，遍历用户指定的 <code>target_modules</code>，把原始的 <code>nn.Linear</code> 或 <code>Conv1D</code> 层替换成我们前面写好的 <code>lora_mogai.layer.Linear</code>。  </li>
<li><strong>动态注册</strong>：根据 <code>MogaiConfig</code> 里配置的 <code>r</code>、<code>mogai_alpha</code>、<code>mogai_dropout</code> 等参数，调用 <code>Linear</code> 中的 <code>update_layer</code> 方法，初始化或更新对应层的 LoRA 参数。  </li>
<li><strong>保存/恢复状态</strong>：在 <code>_replace_module</code> 里，还会保留被替换层可能携带的 <code>.state</code>（例如缓存、RNN 隐状态等），确保替换后模型行为一致。  </li>
<li><strong>开关与合并</strong>：实现了 <code>set_adapter</code>、<code>enable_adapter_layers</code> / <code>disable_adapter_layers</code>、<code>merge_and_unload</code> 等方法，让你可在训练、推理、部署时灵活地打开、关闭或将 LoRA 增量固化到原模型。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># lora_mogai/model.py 中的核心片段</span><br><span class="hljs-keyword">from</span> peft.tuners.tuners_utils <span class="hljs-keyword">import</span> BaseTuner<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MogaiModel</span>(<span class="hljs-title class_ inherited__">BaseTuner</span>):<br>    prefix = <span class="hljs-string">"mogai_"</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model, config, adapter_name</span>):<br>        <span class="hljs-built_in">super</span>().__init__(model, config, adapter_name)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_create_and_replace</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        mogai_config,</span><br><span class="hljs-params">        adapter_name,</span><br><span class="hljs-params">        target,</span><br><span class="hljs-params">        target_name,</span><br><span class="hljs-params">        parent,</span><br><span class="hljs-params">        current_key,</span><br><span class="hljs-params">        **optional_kwargs,</span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-keyword">if</span> current_key <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">"Current Key shouldn't be `None`"</span>)<br><br>        pattern = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">r'layers\.(\d+)\.(.+)'</span>)<br>        <span class="hljs-keyword">match</span> = pattern.search(current_key)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">match</span>:<br>            layer_id = <span class="hljs-built_in">int</span>(<span class="hljs-keyword">match</span>.group(<span class="hljs-number">1</span>))<br>            module_name = <span class="hljs-keyword">match</span>.group(<span class="hljs-number">2</span>).replace(<span class="hljs-string">'.'</span>, <span class="hljs-string">'__'</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">"Invalid target module type"</span>)<br><br>        r = mogai_config.r<br>        kwargs = {<br>            <span class="hljs-string">"r"</span>: r,<br>            <span class="hljs-string">"mogai_alpha"</span>: mogai_config.mogai_alpha,<br>            <span class="hljs-string">"mogai_dropout"</span>: mogai_config.mogai_dropout,<br>            <span class="hljs-string">"fan_in_fan_out"</span>: mogai_config.fan_in_fan_out,<br>            <span class="hljs-string">"bias"</span>: mogai_config.bias<br>        }<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(target, Linear):<br>            target.update_layer(<br>                adapter_name,<br>                module_name,<br>                r,<br>                mogai_config.mogai_alpha,<br>                mogai_config.mogai_dropout,<br>            )<br>        <span class="hljs-keyword">else</span>:<br>            new_module = <span class="hljs-variable language_">self</span>._create_new_module(mogai_config, adapter_name, target, module_name, **kwargs)<br>            <span class="hljs-keyword">if</span> adapter_name <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.active_adapter:<br>                new_module.requires_grad_(<span class="hljs-literal">False</span>)<br>            <span class="hljs-variable language_">self</span>._replace_module(parent, target_name, new_module, target)<br><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_create_new_module</span>(<span class="hljs-params">mogai_config, adapter_name, target, module_name, **kwargs</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(target, BaseTunerLayer):<br>            target_base_layer = target.get_base_layer()<br>        <span class="hljs-keyword">else</span>:<br>            target_base_layer = target<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(target_base_layer, torch.nn.Linear):<br>            <span class="hljs-keyword">if</span> kwargs[<span class="hljs-string">"fan_in_fan_out"</span>]:<br>                warnings.warn(<br>                    <span class="hljs-string">"fan_in_fan_out is set to True but the target module is `torch.nn.Linear`. "</span><br>                    <span class="hljs-string">"Setting fan_in_fan_out to False."</span><br>                )<br>                kwargs[<span class="hljs-string">"fan_in_fan_out"</span>] = mogai_config.fan_in_fan_out = <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(target_base_layer, Conv1D):<br>            kwargs[<span class="hljs-string">"is_target_conv_1d_layer"</span>] = <span class="hljs-literal">True</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> kwargs[<span class="hljs-string">"fan_in_fan_out"</span>]:<br>                warnings.warn(<br>                    <span class="hljs-string">"fan_in_fan_out is set to False but the target module is `Conv1D`. "</span><br>                    <span class="hljs-string">"Setting fan_in_fan_out to True."</span><br>                )<br>                kwargs[<span class="hljs-string">"fan_in_fan_out"</span>] = mogai_config.fan_in_fan_out = <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<br>                <span class="hljs-string">f"Target module <span class="hljs-subst">{target}</span> is not supported. Currently, only the following modules are supported: "</span><br>                <span class="hljs-string">"`torch.nn.Linear`, `transformers.pytorch_utils.Conv1D`."</span><br>            )<br>        new_module = Linear(<br>            target,<br>            adapter_name,<br>            module_name,<br>            **kwargs,<br>        )<br><br>        <span class="hljs-keyword">return</span> new_module<br><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_replace_module</span>(<span class="hljs-params">parent, child_name, new_module, child</span>):<br>        <span class="hljs-comment"># 保留 child.state，拷贝到 new_module</span><br>        <span class="hljs-comment"># 将 new_module 移动到原来 device 上</span><br>        <span class="hljs-built_in">setattr</span>(parent, child_name, new_module)<br>        <span class="hljs-comment"># It's not necessary to set requires_grad here, as that is handled by</span><br>        <span class="hljs-comment"># _mark_only_adapters_as_trainable</span><br><br>        <span class="hljs-comment"># child layer wraps the original module, unpack it</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(child, <span class="hljs-string">"base_layer"</span>):<br>            child = child.base_layer<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">hasattr</span>(new_module, <span class="hljs-string">"base_layer"</span>):<br>            new_module.weight = child.weight<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(child, <span class="hljs-string">"bias"</span>):<br>                new_module.bias = child.bias<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">getattr</span>(child, <span class="hljs-string">"state"</span>, <span class="hljs-literal">None</span>) <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(new_module, <span class="hljs-string">"base_layer"</span>):<br>                new_module.base_layer.state = child.state<br>            <span class="hljs-keyword">else</span>:<br>                new_module.state = child.state<br>            new_module.to(child.weight.device)<br><br>        <span class="hljs-comment"># dispatch to correct device</span><br>        <span class="hljs-keyword">for</span> name, module <span class="hljs-keyword">in</span> new_module.named_modules():<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">"mogai_"</span> <span class="hljs-keyword">in</span> name:<br>                module.to(child.weight.device)<br></code></pre></td></tr></table></figure>

<p>下面这个函数是用来标记哪些参数是可训练的，哪些是不可训练的。这个函数会在 <code>PeftModel</code> 的 <code>__init__</code> 函数中被调用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_mark_only_adapters_as_trainable</span>(<span class="hljs-params">self, model: nn.Module</span>) -&gt; <span class="hljs-literal">None</span>:<br>    <span class="hljs-keyword">for</span> n, p <span class="hljs-keyword">in</span> model.named_parameters():<br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.prefix <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> n:<br>            p.requires_grad = <span class="hljs-literal">False</span><br><br>    <span class="hljs-keyword">for</span> active_adapter <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.active_adapters:<br>        bias = <span class="hljs-variable language_">self</span>.peft_config[active_adapter].bias<br>        <span class="hljs-keyword">if</span> bias == <span class="hljs-string">"none"</span>:<br>            <span class="hljs-keyword">continue</span><br><br>        <span class="hljs-keyword">if</span> bias == <span class="hljs-string">"all"</span>:<br>            <span class="hljs-keyword">for</span> n, p <span class="hljs-keyword">in</span> model.named_parameters():<br>                <span class="hljs-keyword">if</span> <span class="hljs-string">"bias"</span> <span class="hljs-keyword">in</span> n:<br>                    p.requires_grad = <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">elif</span> bias == <span class="hljs-string">"mogai_only"</span>:<br>            <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> model.modules():<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, MogaiLayer) <span class="hljs-keyword">and</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">"bias"</span>) <span class="hljs-keyword">and</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                    m.bias.requires_grad = <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> NotImplementedError(<span class="hljs-string">f"Requested bias: <span class="hljs-subst">{bias}</span>, is not implemented."</span>)<br></code></pre></td></tr></table></figure>

<hr>
<h3 id="运行一个完整示例"><a href="#运行一个完整示例" class="headerlink" title="运行一个完整示例"></a>运行一个完整示例</h3><p>下面演示如何直接使用 <code>MogaiModel</code> 进行微调：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM<br><span class="hljs-keyword">from</span> lora_mogai.config <span class="hljs-keyword">import</span> MogaiConfig<br><span class="hljs-keyword">from</span> lora_mogai.model  <span class="hljs-keyword">import</span> MogaiModel<br><br><span class="hljs-comment"># 1. 准备基础模型和配置</span><br>base_model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">"gpt2"</span>)<br>config     = MogaiConfig(<br>    r=<span class="hljs-number">16</span>,<br>    target_modules=[<span class="hljs-string">"q_proj"</span>, <span class="hljs-string">"v_proj"</span>],<br>    mogai_alpha=<span class="hljs-number">32</span>,<br>    mogai_dropout=<span class="hljs-number">0.05</span>,<br>)<br><br><span class="hljs-comment"># 2. 用 MogaiModel 包装（会自动替换指定层）</span><br>mogai = MogaiModel(base_model, config, adapter_name=<span class="hljs-string">"default"</span>)<br><br><span class="hljs-comment"># 3. 继续使用 Trainer 或Torch原生训练循环</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer, TrainingArguments<br><br>training_args = TrainingArguments(<br>    output_dir=<span class="hljs-string">"./mogai_output"</span>,<br>    num_train_epochs=<span class="hljs-number">3</span>,<br>    per_device_train_batch_size=<span class="hljs-number">4</span>,<br>    learning_rate=<span class="hljs-number">1e-4</span>,<br>)<br>trainer = Trainer(<br>    model=mogai.model,                <span class="hljs-comment"># 拿到适配后的模型</span><br>    args=training_args,<br>    train_dataset=your_dataset,       <span class="hljs-comment"># 用户自己准备的数据集</span><br>)<br>trainer.train()<br></code></pre></td></tr></table></figure>


<h2 id="Mix-Mode"><a href="#Mix-Mode" class="headerlink" title="Mix Mode"></a>Mix Mode</h2><p><code>get_peft_model</code> 会返回两种class PeftModel和 PeftMixedModel。需要在call <code>get_peft_model</code>时指定<code>mixed=True</code>. 需要在 <code>/src/peft/tuners/mixed/model.py</code> 中把新创建的module加入到Comptaible Tuner中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">"Qwen/Qwen3-0.6B-Base"</span>)<br><span class="hljs-comment"># model.add_adapter("adapters1", mogai_config)</span><br>peft_model = get_peft_model(model, mogai_config, <span class="hljs-string">"adapters1"</span>, mixed=<span class="hljs-literal">True</span>)<br>peft_model.add_adapter(<span class="hljs-string">"adapters2"</span>, mogai_config)<br>peft_model.add_adapter(<span class="hljs-string">"adapters3"</span>, mogai_config)<br>peft_model.add_adapter(<span class="hljs-string">"adapters4"</span>, mogai_config)<br><br>peft_model.set_adapter([<span class="hljs-string">"adapters1"</span>, <span class="hljs-string">"adapters2"</span>, <span class="hljs-string">"adapters3"</span>, <span class="hljs-string">"adapters4"</span>])<br><span class="hljs-comment"># peft_model.set_adapter("adapters1")</span><br><br><span class="hljs-built_in">print</span>(peft_model.active_adapters)<br></code></pre></td></tr></table></figure>
        </div>
        
        <!-- 文章导航 -->
        <nav class="post-nav">
          
          
            <a class="next" href="/2025/04/30/Peft-Finetuning-RL/">
              RLHF
              <i class="fas fa-chevron-right"></i>
            </a>
          
        </nav>
      </article>
    </div>
  </div>
</div>

    </div>
    <footer class="footer">
  <div class="status-bar">
    <div class="status-item">
      <i class="fas fa-code-branch"></i>
      master
    </div>
    <div class="status-item">
      <i class="fas fa-sync"></i>
      Tuntun
    </div>
    <div class="status-item">
      <i class="fas fa-clock"></i>
      2025-05-03
    </div>
    <div class="status-item">
      Designed By&nbsp; <a href="https://github.com/B143KC47" target="_blank"> BlackCat</a>
    </div>
    <div class="status-item github">
      <a href="#" target="_blank">
        <i class="fab fa-github"></i>
      </a>
    </div>
  </div>
</footer>

    
    <!-- 全局配置 -->
    <script>
      window.HEXO_CONFIG = {
        language: "en",
        root: "/"
      };
      
      // 特定于搜索的配置
      window.VSC4T_SEARCH = {
        root: "/"
      };
    </script>
    
    <script src="//cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>
    <script src="//cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
    <script src="//cdn.jsdelivr.net/npm/highlight.js@11.7.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <!-- 这里可以放置自定义脚本 -->
<script>
document.addEventListener('DOMContentLoaded', (event) => {
  // Apply smooth scroll to non-TOC anchor links
  document.querySelectorAll('a[href^="#"]:not(.toc-link)').forEach(anchor => {
    anchor.addEventListener('click', function (e) {
      e.preventDefault();
      // Check if querySelector is valid before using it
      try {
        const targetSelector = this.getAttribute('href');
        // Basic check for potentially invalid selectors (though not exhaustive)
        if (targetSelector && targetSelector.length > 1) { 
          const targetElement = document.querySelector(targetSelector);
          if (targetElement) {
            targetElement.scrollIntoView({
              behavior: 'smooth'
            });
          } else {
            console.warn('Smooth scroll target not found:', targetSelector);
          }
        } else {
           console.warn('Invalid href for smooth scroll:', targetSelector);
        }
      } catch (error) {
        console.error('Error during smooth scroll:', error, 'Selector:', this.getAttribute('href'));
        // Fallback or alternative behavior if needed
        // For example, try getElementById if it's just an ID
        const targetId = this.getAttribute('href').slice(1);
        try {
            const targetElementById = document.getElementById(decodeURIComponent(targetId));
            if (targetElementById) {
                targetElementById.scrollIntoView({ behavior: 'smooth' });
            }
        } catch (idError) {
             console.error('Fallback getElementById also failed:', idError);
        }
      }
    });
  });
});
</script>
<script src="/js/toc.js"></script>

<!-- Scripts -->
<script>
  // 将语言文件中的翻译传递给前端
  window.HEXO_CONFIG = {
    language: "en",
    search_placeholder: "Type to search...",
    search_no_results: "No results found",
    search_result: "result",
    search_results: "results",
    search_results_found: "Found undefined results",
    search_in: "Search in",
    search_in_title: "Title",
    search_in_content: "Content",
    search_in_tags: "Tags",
    search_in_categories: "Categories",
    search_filters: "Search Filters",
    search_recent: "Recent Searches",
    search_clear: "Clear",
    search_loading: "Loading...",
    search_error: "Error loading search data"
  };
</script>



<!-- 添加所有需要的脚本 -->
<script src="/js/main.js"></script>
<script src="/js/search.js"></script>


    <script>
      // 移动端菜单切换
      $(document).ready(function() {
        $('.mobile-menu-toggle').click(function() {
          $('.sidebar-explorer').toggleClass('show');
        });
      });
    </script>
  </body>
</html>
